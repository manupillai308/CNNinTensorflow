{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_mldata('mnist original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = data.data[:], data.target[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for i in range(x_data.shape[0]):\n",
    "    if y_data[i] > 5:\n",
    "        indexes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.delete(x_data, indexes, axis=0)\n",
    "y_data = np.delete(y_data, indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42048, 784), (42048,))"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5.]),\n",
       " array([6903, 7877, 6990, 7141, 6824, 6313], dtype=int64))"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_data, return_counts= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.reshape((x_data.shape[0],height, width, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_data[67000], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "sssplit = StratifiedShuffleSplit(random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_train_index, x_test_index in sssplit.split(x_data, y_data):\n",
    "    x_train, y_train = x_data[x_train_index], y_data[x_train_index]\n",
    "    x_test, y_test = x_data[x_test_index], y_data[x_test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size = 50, x_train = x_train, y_train = y_train):\n",
    "    prev = 0\n",
    "    for i in range(batch_size , x_train.shape[0], batch_size):\n",
    "        yield x_train[prev:i], y_train[prev:i]\n",
    "        prev = i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 28, 28, 1)"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(next_batch())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 28\n",
    "width = 28\n",
    "channels = 1\n",
    "learning_rate = 0.001\n",
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "data_size = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"input\"):\n",
    "    X = tf.placeholder(shape = (None, height, width, channels), dtype = tf.float32)\n",
    "    y = tf.placeholder(shape = (None), dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"cnn\"):\n",
    "    conv1 = tf.layers.conv2d(X, filters= 2, kernel_size= 7, strides=[1,1], padding = \"SAME\", name = \"CONV1\")\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = \"VALID\", name = \"POOL1\")\n",
    "    conv2 = tf.layers.conv2d(pool1, filters = 3, kernel_size = 3, strides=[2,2], padding = \"SAME\", name = \"CONV2\")\n",
    "    pool2 = tf.nn.avg_pool(conv2, ksize = [1,3,3,1], strides = [1,1,1,1], padding = \"VALID\", name = \"POOL2\")\n",
    "    flatten = tf.layers.flatten(pool2, name = \"FLATTEN\")\n",
    "    dense1 = tf.layers.dense(inputs=flatten, units = 20, activation=tf.nn.elu, kernel_initializer= he_init, name = \"DENSE1\")\n",
    "    logits = tf.layers.dense(inputs= dense1, units=10, activation = None, kernel_initializer= he_init, name = \"LOGITS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"gradients\"):\n",
    "    grad = tf.train.MomentumOptimizer(momentum = 0.9,learning_rate= learning_rate, use_nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels= y, name = \"xENTROPY\")\n",
    "    loss = tf.reduce_mean(xentropy, name = \"LOSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"accuracy\"):\n",
    "    pred = tf.nn.in_top_k(k=1, predictions=logits, targets=y, name = \"PREDICTIONS\")\n",
    "    acc = tf.reduce_mean(tf.cast(pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"training_op\"):\n",
    "    training_op = grad.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 Training accuracy: 0.84 Testing accuracy: 0.8416171\n",
      "epoch 1 Training accuracy: 0.88 Testing accuracy: 0.89298457\n",
      "epoch 2 Training accuracy: 0.92 Testing accuracy: 0.91034484\n",
      "epoch 3 Training accuracy: 0.92 Testing accuracy: 0.9210464\n",
      "epoch 4 Training accuracy: 0.94 Testing accuracy: 0.9300832\n",
      "epoch 5 Training accuracy: 0.96 Testing accuracy: 0.934126\n",
      "epoch 6 Training accuracy: 0.96 Testing accuracy: 0.93626636\n",
      "epoch 7 Training accuracy: 0.96 Testing accuracy: 0.9426873\n",
      "epoch 8 Training accuracy: 0.98 Testing accuracy: 0.94791913\n",
      "epoch 9 Training accuracy: 0.98 Testing accuracy: 0.95386446\n",
      "epoch 10 Training accuracy: 0.98 Testing accuracy: 0.9571938\n",
      "epoch 11 Training accuracy: 0.98 Testing accuracy: 0.9629013\n",
      "epoch 12 Training accuracy: 0.98 Testing accuracy: 0.96504164\n",
      "epoch 13 Training accuracy: 0.98 Testing accuracy: 0.9671819\n",
      "epoch 14 Training accuracy: 0.98 Testing accuracy: 0.96956\n",
      "epoch 15 Training accuracy: 0.98 Testing accuracy: 0.97217596\n",
      "epoch 16 Training accuracy: 0.98 Testing accuracy: 0.9740785\n",
      "epoch 17 Training accuracy: 0.98 Testing accuracy: 0.97621876\n",
      "epoch 18 Training accuracy: 0.98 Testing accuracy: 0.9764566\n",
      "epoch 19 Training accuracy: 0.98 Testing accuracy: 0.9781213\n",
      "epoch 20 Training accuracy: 0.98 Testing accuracy: 0.979786\n",
      "epoch 21 Training accuracy: 0.98 Testing accuracy: 0.9807372\n",
      "epoch 22 Training accuracy: 0.98 Testing accuracy: 0.98097503\n",
      "epoch 23 Training accuracy: 0.98 Testing accuracy: 0.98121285\n",
      "epoch 24 Training accuracy: 0.98 Testing accuracy: 0.9821641\n",
      "epoch 25 Training accuracy: 0.98 Testing accuracy: 0.9821641\n",
      "epoch 26 Training accuracy: 0.98 Testing accuracy: 0.98192626\n",
      "epoch 27 Training accuracy: 0.98 Testing accuracy: 0.9821641\n",
      "epoch 28 Training accuracy: 0.98 Testing accuracy: 0.9821641\n",
      "epoch 29 Training accuracy: 0.98 Testing accuracy: 0.9824019\n",
      "epoch 30 Training accuracy: 0.98 Testing accuracy: 0.98263973\n",
      "epoch 31 Training accuracy: 0.98 Testing accuracy: 0.98263973\n",
      "epoch 32 Training accuracy: 0.98 Testing accuracy: 0.98263973\n",
      "epoch 33 Training accuracy: 0.98 Testing accuracy: 0.9831153\n",
      "epoch 34 Training accuracy: 1.0 Testing accuracy: 0.98335314\n",
      "epoch 35 Training accuracy: 1.0 Testing accuracy: 0.9840666\n",
      "epoch 36 Training accuracy: 1.0 Testing accuracy: 0.9840666\n",
      "epoch 37 Training accuracy: 1.0 Testing accuracy: 0.9845422\n",
      "epoch 38 Training accuracy: 1.0 Testing accuracy: 0.98478\n",
      "epoch 39 Training accuracy: 1.0 Testing accuracy: 0.98478\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        batch = next_batch(batch_size=batch_size)\n",
    "        for iteration in range(data_size//batch_size):\n",
    "            try:\n",
    "                x_Train, y_Train = next(batch)\n",
    "            except StopIteration:\n",
    "                pass\n",
    "            else:\n",
    "                sess.run(training_op, feed_dict = {X:x_Train, y: y_Train})\n",
    "        acc_train = acc.eval(feed_dict = {X: x_Train, y:y_Train})\n",
    "        acc_test = acc.eval(feed_dict = {X: x_test, y: y_test})\n",
    "        print(\"epoch\", epoch, \"Training accuracy:\", acc_train, \"Testing accuracy:\", acc_test)\n",
    "    saver.save(sess, './mymodel.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
